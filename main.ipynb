{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD, NMF, LatentDirichletAllocation\n",
    "from sklearn.naive_bayes import MultinomialNB,ComplementNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_train = '...'\n",
    "df_train = pd.read_csv(file_path_train, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels have six distinct values, however, we only want to distinguish whether a record has label 'pants-fire', so let us map all other labels to 'other', so that we have only two labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_mapped = df_train[\"label\"].map(lambda x: x if (x == \"pants-fire\") else \"other\")\n",
    "y = {'label': labels_mapped}\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the set is balanced. As we can see, the label 'pants-fire' makes up only ca. 9% of the set. We will use the ratio counts_val later when fitting Xgboost in order to try to counteract this imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other         9426\n",
       "pants-fire     842\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts=labels_mapped.value_counts()\n",
    "counts[1]/(counts[0]+counts[1])\n",
    "counts_val = counts[1]/counts[0]\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns state and speaker_job contain both NaN and None values. I assume that every speaker belongs to a state, we just don't have the information about it, hence NaN and None have the same meaning. When it comes to the job, there are only 3 entries with None: fulton county house of wellness and anonynomous activist. Again, I believe that None just means that the information wasn't obtained and not that any of them was unemployed, so I have decided to map all None values to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_mapped = df_train[\"state\"].map(lambda x: x if (x != \"None\") else np.nan)\n",
    "speaker_job_mapped = df_train[\"speaker_job\"].map(lambda x: x if (x != \"None\") else np.nan)\n",
    "mapped_cols = {'state': state_mapped, 'speaker_job': speaker_job_mapped}\n",
    "mapped_cols_df = pd.DataFrame(mapped_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to prepare the columns for their encoding. I have decided to use one hot encoding for the columns 'speaker', 'speaker_job', 'state', 'party', since they do not contain a lot of text. I want to tokenize the other columns. To facilitate that, I merge the columns 'statement', 'subject' and 'context' into one column that I name 'text'.\n",
    "Both, the OneHotEncoder and TfIdfVectorizer have a problem with nan values, so I replace all nan values in all columns with 'missing_value'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"text\"] = df_train[\"statement\"]+df_train[\"subject\"]+df_train[\"context\"].fillna('') \n",
    "df_train_mapped = pd.concat([df_train[\"text\"], state_mapped, speaker_job_mapped, df_train[\"speaker\"], df_train[\"party\"]], \n",
    "                            axis = 1)\n",
    "df_train_mapped = df_train_mapped.fillna(\"missing_value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: This was my first ML project. Today, I would have just done stratified sampling.\n",
    "\n",
    "As a final step, I have decided to split the training data into a true training set and a holdout set on which I can test my model. I have chosen a very small holdout set size, because the amount of \n",
    "pants-fire' recors is very low and I didn't want risk having all of them in the holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df_train_mapped, y, test_size=0.05, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prepped data looks like that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>state</th>\n",
       "      <th>speaker_job</th>\n",
       "      <th>speaker</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4676</th>\n",
       "      <td>Since 2010, America has put more people back t...</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>President</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>Even when all other state agencies took cuts, ...</td>\n",
       "      <td>missing_value</td>\n",
       "      <td>missing_value</td>\n",
       "      <td>GaGOP</td>\n",
       "      <td>republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7634</th>\n",
       "      <td>\"First, he said he would take all of our troop...</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>U.S. senator</td>\n",
       "      <td>joe-biden</td>\n",
       "      <td>democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780</th>\n",
       "      <td>Says $30 million gap in stadium funding forced...</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Mayor of Portland</td>\n",
       "      <td>sam-adams</td>\n",
       "      <td>democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4741</th>\n",
       "      <td>Says Sen. Rand Pauls 2011 budget included a bi...</td>\n",
       "      <td>missing_value</td>\n",
       "      <td>missing_value</td>\n",
       "      <td>doug-muder</td>\n",
       "      <td>democrat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text          state  \\\n",
       "4676  Since 2010, America has put more people back t...       Illinois   \n",
       "2513  Even when all other state agencies took cuts, ...  missing_value   \n",
       "7634  \"First, he said he would take all of our troop...       Delaware   \n",
       "8780  Says $30 million gap in stadium funding forced...         Oregon   \n",
       "4741  Says Sen. Rand Pauls 2011 budget included a bi...  missing_value   \n",
       "\n",
       "            speaker_job       speaker       party  \n",
       "4676          President  barack-obama    democrat  \n",
       "2513      missing_value         GaGOP  republican  \n",
       "7634       U.S. senator     joe-biden    democrat  \n",
       "8780  Mayor of Portland     sam-adams    democrat  \n",
       "4741      missing_value    doug-muder    democrat  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing and Conversion to Table Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's start preprocessing the 'text' column. I wanted to exclude stop words, very short words, special characters and numbers and to incorporate stemming. Still, the amount of attributed would be huge, so I have decided to set a maximum amount of features. Therefore I have defined the following vectorizer (I use the tf-idf statistic, so I based the vectorizer on TfidfVectorizer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemmingVectorizer(TfidfVectorizer):\n",
    "    def build_tokenizer(self):\n",
    "        self.ps = PorterStemmer()\n",
    "        tokenize = super().build_tokenizer()\n",
    "        return lambda doc: [self.ps.stem(w) for w in tokenize(doc) if (w not in stopwords.words('english') and len(w)>2)]\n",
    "    def __init__(self):\n",
    "        super(StemmingVectorizer, self).__init__()\n",
    "        self.token_pattern = '[a-zA-Z]*'\n",
    "        self.max_features = 1000\n",
    "        self.stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply it to the 'text' column of the training set and OneHotEncoder to the other columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_trans = ColumnTransformer([('text_tokenizer',  StemmingVectorizer(), 'text'),\n",
    "                                    ('one_hot', OneHotEncoder(dtype='int', handle_unknown='ignore'), \n",
    "                                     ['state', 'speaker_job', 'speaker', 'party'])],\n",
    "                                 remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_col_trans = column_trans.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9754, 5064)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_col_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_col_trans.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction and Fitting a Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, I have created a pipeline that includes dimensionality reduction and classifier fitting. I have decided to start with fitting a Random Forest as a benchmark for the later models since it is efficient for large data sets (allows for parallell processing) and helps avoid overfitting thanks to bagging. I have also tried other models, shown later.\n",
    "\n",
    "As for dimensionality reduction, I have decided to fit all three methods that have been introcuded during the lectures, because it's easy to check them all. To fit the dimensionality reduction method and the parameters for the classifier I use GridSearchCV.\n",
    "\n",
    "Since fitting the model to the training set takes quite a long time, I pickled it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('reduce_dim', NMF()), ('classify', RandomForestClassifier())])\n",
    "\n",
    "params = {\n",
    "    'reduce_dim': [TruncatedSVD(), NMF(), LatentDirichletAllocation()],\n",
    "    'reduce_dim__n_components': [10, 50, 100],\n",
    "    'classify__n_estimators': [10, 50, 100, 150],\n",
    "    'classify__max_features': ['sqrt', 'log2'],\n",
    "    'classify__min_samples_leaf': [1, 5, 10],\n",
    "    'classify__max_depth': [50, 100, 200, None]\n",
    "}\n",
    "opt = GridSearchCV(pipe, param_grid=params, n_jobs=-1, scoring='roc_auc', cv = 5, verbose = 11)\n",
    "opt.fit(fitted_col_trans, y_train)\n",
    "print(opt.best_params_)\n",
    "est = opt.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'classify__max_depth': None, 'classify__max_features': 'sqrt', 'classify__min_samples_leaf': 5, 'classify__n_estimators': 10, 'reduce_dim': TruncatedSVD(algorithm='randomized', n_components=100, n_iter=5,\n",
    "       random_state=None, tol=0.0), 'reduce_dim__n_components': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('RF.pkl', 'wb') as fid:\n",
    "    pickle.dump(est, fid)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us transform the holdout set with the column transformer (i.e. OneHotEncoder and StemmingVEctorizer) and then with the fitted model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('RF.pkl', 'rb') as fp:\n",
    "    est2 = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_col_trans_val = column_trans.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_val = est2.predict(fitted_col_trans_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the model will be markers based on the area under the ROC curve, I wanted to find the AUC on the holdoutset.\n",
    "Therefore, I had to binarize the labels (1 = 'pants-fire', 0 = 'other') of the predicted labels and the target labels and transform them into lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "514"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_pred_binary = list(map(lambda x: 1 if (x == \"pants-fire\") else 0, predicted_val))\n",
    "\n",
    "y_val_target=y_val.to_numpy()\n",
    "y_val_target_shaped = y_val_target.transpose()[0]\n",
    "\n",
    "y_val_target_binary = list(map(lambda x: 1 if (x == \"pants-fire\") else 0, y_val_target_shaped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.882217847769029"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_score = roc_auc_score(y_val_pred_binary, y_val_target_binary)\n",
    "roc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The picked model:\n",
    "Dimensionality Reduction: TruncatedSVD(algorithm='randomized', n_components=100, n_iter=5, random_state=None, tol=0.0)\n",
    "Classifier: RandomForestClassifier(max_depth = None, classify_max_features = 'sqrt', classify_mean_samples_leaf = 5,\n",
    "                                  classify_n_estimators = 10)\n",
    "AUC on holdout set: 0.89"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation of Test Set and Export of Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Turns out, that the first model I tried got the best AUC on the holdout set, so I will transform the test set with this model. At the botton of the notebook you can find the other models I have tried and their AUCs, however, I didn't use them in the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to prepare the test set the same way as the train set, so let us prepare the test set by mapping Nones to nan in the appropriate columns, merging the same columns as for the train set and the using the column transformer that was fitted to the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_test = '...'\n",
    "df_test = pd.read_csv(file_path_test, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_mapped_test = df_test[\"state\"].map(lambda x: x if (x != \"None\") else np.nan)\n",
    "speaker_job_mapped_test = df_test[\"speaker_job\"].map(lambda x: x if (x != \"None\") else np.nan)\n",
    "mapped_cols_test = {'state': state_mapped_test, 'speaker_job': speaker_job_mapped_test}\n",
    "mapped_cols_df_test = pd.DataFrame(mapped_cols_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"text\"] = df_test[\"statement\"]+df_test[\"subject\"]+df_test[\"context\"].fillna('') \n",
    "df_test_mapped = pd.concat([df_test[\"text\"], state_mapped_test, speaker_job_mapped_test, df_test[\"speaker\"], df_test[\"party\"]], axis = 1)\n",
    "df_test_mapped = df_test_mapped.fillna(\"missing_value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_col_trans_test = column_trans.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test = est2.predict(fitted_col_trans_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test_df = pd.DataFrame(predicted_test, columns = ['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model predicted very few 'pants-fire' labels, which was to be expected, but the ratio of the predicted 'pants-fire' labels to 'other' was much lower than in training set, which is a bit worrisome. There is probably room for improvement, but due to the deadline I have decided to go with this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017153996101364522"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_test = predicted_test_df['label'].value_counts()\n",
    "counts_test[1]/(counts_test[0]+counts_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predictions.res', 'a') as file:\n",
    "     file.write(predicted_test_df.to_string(header = False, index = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have also tried fitting XGboost. I set scale_pos_weight to the ratio of 'other' labels to 'pants-fire' labels in order to counteract the imbalance a bit. I also set subsample to 0.8 to minimize overfitting. However, the AUC on the holdout set was 0.6, which isn't a good result. It would probably take quite some time to find the correct parameter values to be tested in order to beat the RandomForestClassifier, so I decied to stick with the random forest.\n",
    "I have also tried a Bayes classifier, which was very quick, since I only fitted one parameter, however the resulting AUC was 0.46."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe3 = Pipeline([('reduce_dim', NMF()), ('classify', xgb.XGBClassifier(scale_pos_weight = 1/counts_val, subsample = 0.8))])\n",
    "\n",
    "params3 = {\n",
    "    'reduce_dim': [TruncatedSVD(), NMF(), LatentDirichletAllocation()],\n",
    "    'reduce_dim__n_components': [10, 50, 100],\n",
    "    'classify__n_estimators': [50, 100],\n",
    "    'classify__eta': [0.001, 0.01, 0.1],\n",
    "    'classify__max_depth': [3, 6, 9]\n",
    "}\n",
    "opt3 = GridSearchCV(pipe3, param_grid=params3, n_jobs=-1, scoring='roc_auc', cv = 5, verbose = 11)\n",
    "opt3.fit(fitted_col_trans, y_train)\n",
    "print(opt3.best_params_)\n",
    "est3 = opt3.best_estimator_\n",
    "with open('xgboost2.pkl', 'wb') as fid:\n",
    "    pickle.dump(est3, fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'classify__eta': 0.1, 'classify__max_depth': 9, 'classify__n_estimators': 100, 'reduce_dim': TruncatedSVD(algorithm='randomized', n_components=100, n_iter=5,\n",
    "       random_state=None, tol=0.0), 'reduce_dim__n_components': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6121598639455782"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_predicted3 = est3.predict(fitted_col_trans_val)\n",
    "y_val_pred_binary3 = list(map(lambda x: 1 if (x == \"pants-fire\") else 0, y_val_predicted3))\n",
    "\n",
    "y_val_target=y_val.to_numpy()\n",
    "y_val_target_shaped = y_val_target.transpose()[0]\n",
    "\n",
    "y_val_target_binary = list(map(lambda x: 1 if (x == \"pants-fire\") else 0, y_val_target_shaped))\n",
    "roc_score3 = roc_auc_score(y_val_pred_binary3, y_val_target_binary)\n",
    "roc_score3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes approach:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "pipe4 = Pipeline([('classify', ComplementNB())])\n",
    "\n",
    "params4 = {\n",
    "    \n",
    "    'classify__alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1., 1.5]\n",
    "    \n",
    "}\n",
    "opt4 = GridSearchCV(pipe4, param_grid=params4, n_jobs=-1, scoring='roc_auc', cv = 5, verbose = 11)\n",
    "opt4.fit(fitted_col_trans, y_train)\n",
    "print(opt4.best_params_)\n",
    "est4 = opt4.best_estimator_\n",
    "with open('ComplementNB.pkl', 'wb') as fid:\n",
    "    pickle.dump(est4, fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'classify__alpha': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46101364522417154"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_predicted4 = est4.predict(fitted_col_trans_val)\n",
    "y_val_pred_binary4 = list(map(lambda x: 1 if (x == \"pants-fire\") else 0, y_val_predicted4))\n",
    "roc_score4 = roc_auc_score(y_val_pred_binary4, y_val_target_binary)\n",
    "roc_score4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
